"""å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨ - æ¯æ—¥æ¨¡å¼éªŒè¯å’Œå‡†ç¡®ç‡ç»Ÿè®¡"""
import schedule
import time
from datetime import datetime
import os
from .database import StockDatabase
from .analyzer import StockAnalyzer
from .pattern_matcher import load_classic_patterns
import json

class PatternScheduler:
    """æ¨¡å¼è¯†åˆ«å®šæ—¶ä»»åŠ¡"""

    def __init__(self, db_path: str = "../data/stocks.db", api_key: str = None):
        self.db = StockDatabase(db_path)
        self.api_key = api_key or os.environ.get('ANTHROPIC_API_KEY')

        if not self.api_key:
            raise ValueError("æœªè®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")

        self.analyzer = StockAnalyzer(self.api_key)

    def daily_prediction(self):
        """æ¯æ—¥é¢„æµ‹ä»»åŠ¡ï¼ˆåœºæ™¯äºŒï¼‰"""
        print(f"\n{'='*60}")
        print(f"æ¯æ—¥é¢„æµ‹ä»»åŠ¡å¼€å§‹ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")

        try:
            # è·å–è‚¡ç¥¨æ± æœ€è¿‘30å¤©æ•°æ®
            print("\n1. åŠ è½½è‚¡ç¥¨æ± æ•°æ®...")
            stock_data = self.db.get_recent_data_all_stocks(days=30)
            print(f"   è·å–åˆ° {len(stock_data)} æ¡æ•°æ®")

            # åŠ è½½æ¨¡å¼
            print("\n2. åŠ è½½æ¨¡å¼...")
            patterns = self._load_patterns()
            print(f"   åŠ è½½äº† {len(patterns)} ä¸ªæ¨¡å¼")

            # é¢„æµ‹ï¼ˆå¯ç”¨ç¨‹åºé¢„ç­›é€‰ï¼‰
            print("\n3. å¼€å§‹é¢„æµ‹...")
            predictions = self.analyzer.predict_stock_probability(
                stock_data,
                patterns,
                batch_size=30,
                use_pre_screening=True,
                pattern_file='classic_patterns.json'
            )

            print(f"\n4. é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} åªè‚¡ç¥¨")

            # ä¿å­˜ç»“æœ
            output_file = f"predictions_{datetime.now().strftime('%Y%m%d')}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'predictions': predictions
                }, f, ensure_ascii=False, indent=2)

            print(f"   ç»“æœå·²ä¿å­˜: {output_file}")

            # æ˜¾ç¤ºTop10
            print("\nğŸ“Š Top 10 é¢„æµ‹:")
            for i, pred in enumerate(predictions[:10], 1):
                print(f"   {i}. {pred['code']} ({pred['name']}): {pred['probability']:.1f}%")
                print(f"      {pred['reason']}")

        except Exception as e:
            print(f"âŒ æ¯æ—¥é¢„æµ‹å¤±è´¥: {e}")

    def weekly_accuracy_update(self):
        """æ¯å‘¨å‡†ç¡®ç‡æ›´æ–°ä»»åŠ¡"""
        print(f"\n{'='*60}")
        print(f"æ¯å‘¨å‡†ç¡®ç‡æ›´æ–°ä»»åŠ¡å¼€å§‹ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")

        try:
            # è¿è¡Œå›æµ‹è„šæœ¬
            print("\nè¿è¡Œå›æµ‹è„šæœ¬...")
            import subprocess
            result = subprocess.run(
                ['python', 'backend/scripts/backtest_patterns.py'],
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                print("âœ“ å›æµ‹å®Œæˆ")
                print(result.stdout)
            else:
                print("âŒ å›æµ‹å¤±è´¥")
                print(result.stderr)

            # æ·˜æ±°ä½å‡†ç¡®ç‡æ¨¡å¼
            print("\næ·˜æ±°ä½å‡†ç¡®ç‡æ¨¡å¼...")
            self._deactivate_low_accuracy_patterns(threshold=40.0)

        except Exception as e:
            print(f"âŒ å‡†ç¡®ç‡æ›´æ–°å¤±è´¥: {e}")

    def monthly_pattern_discovery(self):
        """æ¯æœˆæ¨¡å¼å‘ç°ä»»åŠ¡ï¼ˆåœºæ™¯ä¸€ï¼Œ$3.30ï¼‰"""
        print(f"\n{'='*60}")
        print(f"æ¯æœˆæ¨¡å¼å‘ç°ä»»åŠ¡å¼€å§‹ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")

        try:
            print("\nä¾æ¬¡è¿è¡Œï¼š")
            print("1. filter_classic_samples.py")
            print("2. classify_special_samples.py")
            print("3. extract_new_patterns.py")
            print("4. merge_patterns.py")

            scripts = [
                'backend/scripts/filter_classic_samples.py',
                'backend/scripts/classify_special_samples.py',
                'backend/scripts/extract_new_patterns.py',
                'backend/scripts/merge_patterns.py'
            ]

            for script in scripts:
                print(f"\næ‰§è¡Œ: {script}")
                import subprocess
                result = subprocess.run(
                    ['python', script],
                    capture_output=True,
                    text=True
                )

                if result.returncode == 0:
                    print("âœ“ å®Œæˆ")
                else:
                    print(f"âŒ å¤±è´¥: {result.stderr}")
                    break

        except Exception as e:
            print(f"âŒ æ¨¡å¼å‘ç°å¤±è´¥: {e}")

    def _load_patterns(self):
        """ä»æ•°æ®åº“åŠ è½½æ¿€æ´»çš„æ¨¡å¼"""
        conn = self.db.get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT pattern_id, pattern_name, description, characteristics,
                   validated_success_rate, validation_sample_count
            FROM rising_patterns
            WHERE is_active = 1
        ''')

        patterns = []
        for row in cursor.fetchall():
            pattern = {
                'pattern_id': row[0],
                'pattern_name': row[1],
                'description': row[2],
                'characteristics': eval(row[3]) if row[3] else [],
                'validated_success_rate': row[4],
                'validation_sample_count': row[5]
            }
            patterns.append(pattern)

        conn.close()

        if len(patterns) == 0:
            # é™çº§ï¼šä½¿ç”¨ç»å…¸æ¨¡å¼
            print("   æ•°æ®åº“æ— æ¿€æ´»æ¨¡å¼ï¼Œä½¿ç”¨ç»å…¸æ¨¡å¼æ–‡ä»¶")
            classic_patterns = load_classic_patterns('classic_patterns.json')
            for p in classic_patterns:
                patterns.append({
                    'pattern_name': p['pattern_name'],
                    'description': p['description'],
                    'characteristics': []
                })

        return patterns

    def _deactivate_low_accuracy_patterns(self, threshold: float = 40.0):
        """æ·˜æ±°ä½å‡†ç¡®ç‡æ¨¡å¼"""
        conn = self.db.get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            UPDATE rising_patterns
            SET is_active = 0
            WHERE validated_success_rate < ?
                AND validated_success_rate IS NOT NULL
        ''', (threshold,))

        deactivated_count = cursor.rowcount

        conn.commit()
        conn.close()

        print(f"   æ·˜æ±°äº† {deactivated_count} ä¸ªä½å‡†ç¡®ç‡æ¨¡å¼ï¼ˆ<{threshold}%ï¼‰")

    def start(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
        print("ğŸš€ å¯åŠ¨æ¨¡å¼è¯†åˆ«å®šæ—¶ä»»åŠ¡")
        print("\nä»»åŠ¡é…ç½®:")
        print("  - æ¯æ—¥é¢„æµ‹: æ¯å¤© 16:00")
        print("  - å‡†ç¡®ç‡æ›´æ–°: æ¯å‘¨ä¸€ 09:00")
        print("  - æ¨¡å¼å‘ç°: æ¯æœˆ1æ—¥ 08:00")

        # é…ç½®å®šæ—¶ä»»åŠ¡
        schedule.every().day.at("16:00").do(self.daily_prediction)
        schedule.every().monday.at("09:00").do(self.weekly_accuracy_update)
        schedule.every().month.at("08:00").do(self.monthly_pattern_discovery)

        print("\nâ° å®šæ—¶ä»»åŠ¡å·²é…ç½®ï¼Œç­‰å¾…æ‰§è¡Œ...")

        # è¿è¡Œå¾ªç¯
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

def run_once_test():
    """è¿è¡Œä¸€æ¬¡æµ‹è¯•"""
    print("æµ‹è¯•æ¨¡å¼ - è¿è¡Œä¸€æ¬¡æ¯æ—¥é¢„æµ‹")
    scheduler = PatternScheduler()
    scheduler.daily_prediction()

if __name__ == '__main__':
    # æµ‹è¯•è¿è¡Œ
    run_once_test()
