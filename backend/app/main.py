from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import os
import logging
from typing import List

from .database import StockDatabase
from .data_fetcher import StockDataFetcher
from .data_fetcher_baostock import BaoStockDataFetcher
from .data_fetcher_tushare import TushareDataFetcher
from .data_fetcher_akshare import AkShareDataFetcher
from .data_fetcher_yfinance import YahooFinanceDataFetcher
from .analyzer import StockAnalyzer
from .config import get_sample_size, get_rise_threshold
from .data_fetcher_akshare import fetch_sse_component_stocks
from .models import (
    StockPrediction,
    FetchDataRequest,
    AnalyzeRequest,
    AnalysisPattern,
    TrainingRequest
)
from .routers import pattern_training

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
        logging.FileHandler('logs/app.log', encoding='utf-8') if os.path.exists('logs') or os.makedirs('logs', exist_ok=True) else logging.StreamHandler()
    ]
)

# è®¾ç½®ä¸åŒæ¨¡å—çš„æ—¥å¿—çº§åˆ«
logging.getLogger('uvicorn').setLevel(logging.WARNING)
logging.getLogger('httpx').setLevel(logging.WARNING)
logging.getLogger('anthropic').setLevel(logging.INFO)

logger = logging.getLogger(__name__)
logger.info("è‚¡ç¥¨é¢„æµ‹ç³»ç»ŸAPIå¯åŠ¨ä¸­...")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

app = FastAPI(title="è‚¡ç¥¨é¢„æµ‹ç³»ç»ŸAPI")

# æ³¨å†Œè·¯ç”±
app.include_router(pattern_training.router)

# å…è®¸è·¨åŸŸè¯·æ±‚ï¼ˆå‰ç«¯è®¿é—®ï¼‰
# ä»ç¯å¢ƒå˜é‡è¯»å–å…è®¸çš„æºï¼Œé»˜è®¤ä»…localhost
ALLOWED_ORIGINS = os.getenv(
    "ALLOWED_ORIGINS",
    "http://localhost:3000,http://localhost:3001,http://localhost:3002"
).split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],  # æ˜ç¡®æŒ‡å®šå…è®¸çš„æ–¹æ³•
    allow_headers=[
        "Content-Type",
        "Authorization",
        "Accept",
        "Origin",
        "X-Requested-With"
    ],  # æ˜ç¡®æŒ‡å®šå…è®¸çš„headers
    max_age=3600,  # é¢„æ£€è¯·æ±‚ç¼“å­˜1å°æ—¶
)

logger.info(f"CORSé…ç½®: å…è®¸çš„æº = {ALLOWED_ORIGINS}")

# åˆå§‹åŒ–ç»„ä»¶
# ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ DATABASE_PATHï¼›è‹¥æœªè®¾ç½®ï¼Œåˆ™å®šä½åˆ°ä»“åº“æ ¹ç›®å½•ä¸‹çš„ data/stocks.dbï¼Œé¿å…å·¥ä½œç›®å½•å·®å¼‚å¯¼è‡´è¯»å–ç©ºåº“
default_db_path = os.getenv("DATABASE_PATH")
if not default_db_path:
    default_db_path = os.path.normpath(
        os.path.join(os.path.dirname(__file__), "..", "..", "data", "stocks.db")
    )

db = StockDatabase(default_db_path)

# éªŒè¯ API Key å¹¶åˆå§‹åŒ– Analyzerï¼ˆå…è®¸æ— å¯†é’¥å¯åŠ¨ï¼‰
api_key = os.getenv("ANTHROPIC_API_KEY")
if api_key:
    logger.info(f"âœ… API Keyå·²åŠ è½½: {api_key[:20]}...")
    logger.info("   AIåŠŸèƒ½å·²å¯ç”¨")
else:
    logger.warning("âš ï¸  æœªè®¾ç½®ANTHROPIC_API_KEYç¯å¢ƒå˜é‡")
    logger.warning("   ç³»ç»Ÿå°†ä»¥åŸºç¡€æ¨¡å¼è¿è¡Œï¼ŒAIç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨")
    logger.warning("   åŸºç¡€åŠŸèƒ½ï¼ˆæ•°æ®æŠ“å–ã€è‚¡ç¥¨æ± æ›´æ–°ã€ç»Ÿè®¡ï¼‰ä»å¯æ­£å¸¸ä½¿ç”¨")

# æ³¨å…¥æ•°æ®åº“ä¾èµ–ï¼Œå…è®¸æ— API Keyå¯åŠ¨
analyzer = StockAnalyzer(api_key=api_key, db=db)

# å…¨å±€çŠ¶æ€
task_status = {
    "fetch_data": {"running": False, "progress": 0, "message": ""},
    "analyze": {"running": False, "progress": 0, "message": ""},
    "predict": {"running": False, "progress": 0, "message": ""}
}


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "message": "è‚¡ç¥¨é¢„æµ‹ç³»ç»ŸAPIè¿è¡Œä¸­"}


@app.get("/api/statistics")
async def get_statistics():
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = db.get_data_statistics()
        return {
            "success": True,
            "data": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/fetch-data")
async def fetch_data(request: FetchDataRequest, background_tasks: BackgroundTasks):
    """
    åŒºåŸŸ1ï¼šè·å–è‚¡ç¥¨æ•°æ®
    åå°ä»»åŠ¡æ–¹å¼ï¼Œé¿å…è¶…æ—¶
    """
    if task_status["fetch_data"]["running"]:
        return {"success": False, "message": "æ•°æ®è·å–ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­"}

    def fetch_task(years: int):
        try:
            task_status["fetch_data"]["running"] = True
            task_status["fetch_data"]["message"] = "å¼€å§‹è·å–æ•°æ®..."

            # åˆ›å»ºæ•°æ®è·å–å™¨ - æµ‹è¯•Yahoo Finance
            fetcher = YahooFinanceDataFetcher(years=years)  # Yahoo FinanceçœŸå®æ•°æ®
            # fetcher = AkShareDataFetcher(years=years)  # AkShareå…è´¹æ•°æ®ï¼ˆè¿æ¥é—®é¢˜ï¼‰
            # fetcher = TushareDataFetcher(years=years)  # TushareçœŸå®æ•°æ®ï¼ˆéœ€è¦ç§¯åˆ†ï¼‰
            # fetcher = BaoStockDataFetcher(years=years)  # BaoStockçœŸå®æ•°æ®ï¼ˆè¿æ¥é—®é¢˜ï¼‰
            # fetcher = StockDataFetcher(years=years)  # æ¨¡æ‹Ÿæ•°æ®ï¼ˆç¦»çº¿å¯ç”¨ï¼‰

            task_status["fetch_data"]["message"] = "ä»è‚¡ç¥¨æ± è·å–è‚¡ç¥¨åˆ—è¡¨..."
            task_status["fetch_data"]["progress"] = 10

            # ä»è‚¡ç¥¨æ± è·å–è‚¡ç¥¨ä»£ç 
            pool_stocks = db.get_stock_pool(active_only=True)
            if not pool_stocks or len(pool_stocks) == 0:
                task_status["fetch_data"]["message"] = "è‚¡ç¥¨æ± ä¸ºç©ºï¼Œè¯·å…ˆæ›´æ–°è‚¡ç¥¨æ± "
                task_status["fetch_data"]["progress"] = 0
                return

            # è½¬æ¢ä¸ºYahooæ ¼å¼ï¼š6å¼€å¤´åŠ .SSï¼Œ0/3å¼€å¤´åŠ .SZ
            stock_codes = []
            for stock in pool_stocks:
                code = stock.get('code', '')
                if code.startswith('6'):
                    stock_codes.append(f"{code}.SS")
                elif code.startswith(('0', '3')):
                    stock_codes.append(f"{code}.SZ")

            # æ‰‹åŠ¨æŠ“å–è‚¡ç¥¨æ•°æ®ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰
            stock_data_list = []
            incremental_count = 0
            full_fetch_count = 0

            for i, code in enumerate(stock_codes, 1):
                # æ£€æŸ¥è¯¥è‚¡ç¥¨çš„æœ€åæ—¥æœŸ
                stock_code_only = code.split('.')[0]  # å»æ‰.SS/.SZåç¼€
                last_date = db.get_stock_last_date(stock_code_only)

                if last_date:
                    # å¢é‡æ›´æ–°ï¼šåªè·å–æœ€åæ—¥æœŸä¹‹åçš„æ•°æ®
                    data = fetcher.fetch_stock_data(code, start_from=last_date)
                    incremental_count += 1
                    task_status["fetch_data"]["message"] = f"å¢é‡æ›´æ–° {i}/{len(stock_codes)} ({stock_code_only}, ä»{last_date}å¼€å§‹)"
                else:
                    # å…¨é‡è·å–ï¼šè¯¥è‚¡ç¥¨æ²¡æœ‰å†å²æ•°æ®
                    data = fetcher.fetch_stock_data(code)
                    full_fetch_count += 1
                    task_status["fetch_data"]["message"] = f"å…¨é‡è·å– {i}/{len(stock_codes)} ({stock_code_only}, {years}å¹´æ•°æ®)"

                if data:
                    stock_data_list.append(data)

                # æ›´æ–°è¿›åº¦
                progress = 10 + int((i / len(stock_codes)) * 70)
                task_status["fetch_data"]["progress"] = progress

                if i < len(stock_codes):
                    import time
                    time.sleep(0.3)

            if not stock_data_list:
                task_status["fetch_data"]["message"] = "æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
                task_status["fetch_data"]["progress"] = 0
                return

            task_status["fetch_data"]["message"] = "ä¿å­˜åˆ°æ•°æ®åº“..."
            task_status["fetch_data"]["progress"] = 80

            # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆéœ€è¦è½¬æ¢æ ¼å¼ï¼‰
            for stock_data in stock_data_list:
                db.save_single_stock_data(stock_data)

            # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            summary = f"æˆåŠŸï¼"
            if full_fetch_count > 0:
                summary += f"å…¨é‡è·å–{full_fetch_count}åªè‚¡ç¥¨ï¼Œ"
            if incremental_count > 0:
                summary += f"å¢é‡æ›´æ–°{incremental_count}åªè‚¡ç¥¨ï¼Œ"
            summary += f"å…±{len(stock_data_list)}åª"

            task_status["fetch_data"]["message"] = summary
            task_status["fetch_data"]["progress"] = 100

        except Exception as e:
            logger.error(f"æ•°æ®è·å–ä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
            task_status["fetch_data"]["message"] = f"é”™è¯¯: {str(e)}"
            task_status["fetch_data"]["progress"] = 0
        finally:
            task_status["fetch_data"]["running"] = False

    background_tasks.add_task(fetch_task, request.years)

    return {
        "success": True,
        "message": "æ•°æ®è·å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€"
    }


@app.get("/api/task-status/{task_name}")
async def get_task_status(task_name: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_name not in task_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    return {
        "success": True,
        "data": task_status[task_name]
    }


@app.get("/api/claude-api-statistics")
async def get_claude_api_statistics():
    """è·å–Claude APIè°ƒç”¨ç»Ÿè®¡å’Œæˆæœ¬ä¿¡æ¯"""
    try:
        # ä»å…¨å±€analyzerè·å–ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'analyzer' in globals() and analyzer is not None:
            stats = analyzer.get_api_statistics()
            return {
                "success": True,
                "data": stats,
                "message": "APIç»Ÿè®¡ä¿¡æ¯"
            }
        else:
            return {
                "success": False,
                "message": "åˆ†æå™¨æœªåˆå§‹åŒ–",
                "data": {
                    'total_calls': 0,
                    'total_errors': 0,
                    'success_rate': 0,
                    'input_tokens': 0,
                    'output_tokens': 0,
                    'total_tokens': 0,
                    'estimated_cost_usd': 0.0
                }
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


@app.post("/api/analyze")
async def analyze_patterns(request: AnalyzeRequest, background_tasks: BackgroundTasks):
    """
    åŒºåŸŸ2ï¼šåˆ†æä¸Šæ¶¨æ¨¡å¼
    ä½¿ç”¨ Claude AI åˆ†æå†å²æ•°æ®ï¼Œæå–ä¸Šæ¶¨æ¨¡å¼
    """
    logger.info(f"æ”¶åˆ°æ¨¡å¼åˆ†æè¯·æ±‚: pattern_count={request.pattern_count}")

    # æ£€æŸ¥AIæ˜¯å¦å¯ç”¨
    if not analyzer.ai_enabled:
        logger.error("AIåŠŸèƒ½ä¸å¯ç”¨ï¼šæœªé…ç½®ANTHROPIC_API_KEY")
        return {
            "success": False,
            "message": "AIåŠŸèƒ½ä¸å¯ç”¨ï¼šè¯·é…ç½®ANTHROPIC_API_KEYç¯å¢ƒå˜é‡åé‡å¯æœåŠ¡"
        }

    if task_status["analyze"]["running"]:
        logger.warning("åˆ†æä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œæ‹’ç»æ–°è¯·æ±‚")
        return {"success": False, "message": "åˆ†æä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­"}

    def analyze_task(pattern_count: int):
        try:
            logger.info(f"å¼€å§‹åˆ†æä»»åŠ¡: pattern_count={pattern_count}")
            task_status["analyze"]["running"] = True
            task_status["analyze"]["message"] = "è·å–å†å²ä¸Šæ¶¨æ ·æœ¬..."
            task_status["analyze"]["progress"] = 20

            # ä»é…ç½®è·å–æ ·æœ¬é‡å’Œä¸Šæ¶¨é˜ˆå€¼
            sample_size = get_sample_size()
            rise_threshold = get_rise_threshold()

            # ä»æ•°æ®åº“è·å–ä¸Šæ¶¨æ ·æœ¬
            samples = db.get_rising_samples(sample_count=sample_size, rise_threshold=rise_threshold)

            if samples.empty:
                task_status["analyze"]["message"] = f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬ (3å¤©åä¸Šæ¶¨â‰¥{rise_threshold*100}%)"
                return

            task_status["analyze"]["message"] = f"æ‰¾åˆ°{len(samples)}ä¸ªæ ·æœ¬ (ä¸Šæ¶¨â‰¥{rise_threshold*100}%)ï¼Œæ­£åœ¨åˆ†æ..."
            task_status["analyze"]["progress"] = 40

            # Step1: ä½¿ç”¨ Claude åˆ†æ
            patterns = analyzer.analyze_rising_patterns(samples)

            if not patterns:
                task_status["analyze"]["message"] = "åˆ†æå¤±è´¥"
                return

            task_status["analyze"]["message"] = "éªŒè¯æ¨¡å¼æœ‰æ•ˆæ€§ï¼ˆå†å²å›æµ‹ï¼‰..."
            task_status["analyze"]["progress"] = 60

            # Step2: å†å²éªŒè¯ï¼ˆæ–°åŠŸèƒ½ - æ ¸å¿ƒå–ç‚¹ï¼‰
            validation_samples = db.get_validation_samples(days_back=30, rise_threshold=rise_threshold)

            if not validation_samples.empty:
                # ä½¿ç”¨AIæ–¹æ³•éªŒè¯ï¼ˆç²¾ç¡®ä½†æœ‰æˆæœ¬ï¼‰
                # é™åˆ¶éªŒè¯æ ·æœ¬æ•°é‡ï¼ˆé¿å…æˆæœ¬è¿‡é«˜ï¼‰
                max_validation = 100  # æœ€å¤šéªŒè¯100ä¸ªæ ·æœ¬
                if len(validation_samples) > max_validation:
                    validation_samples = validation_samples.sample(n=max_validation, random_state=42)
                    print(f"   ğŸ’¡ éªŒè¯æ ·æœ¬è¿‡å¤šï¼ŒéšæœºæŠ½å–{max_validation}ä¸ªè¿›è¡ŒAIéªŒè¯")

                patterns = analyzer.validate_patterns_ai(patterns, validation_samples, rise_threshold)
            else:
                print("   âš ï¸  æ— éªŒè¯æ•°æ®ï¼Œè·³è¿‡éªŒè¯æ­¥éª¤")

            task_status["analyze"]["message"] = "ä¿å­˜åˆ†æç»“æœ..."
            task_status["analyze"]["progress"] = 80

            # ä¿å­˜æ¨¡å¼ï¼ˆåŒ…å«éªŒè¯ç»“æœï¼‰
            db.save_patterns(patterns)

            task_status["analyze"]["message"] = f"æˆåŠŸï¼è¯†åˆ«å‡º{len(patterns)}ç§æ¨¡å¼ï¼ˆå·²éªŒè¯ï¼‰"
            task_status["analyze"]["progress"] = 100
            logger.info(f"åˆ†æä»»åŠ¡å®Œæˆ: è¯†åˆ«å‡º{len(patterns)}ç§æ¨¡å¼")

        except Exception as e:
            logger.error(f"åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
            task_status["analyze"]["message"] = f"é”™è¯¯: {str(e)}"
        finally:
            task_status["analyze"]["running"] = False

    background_tasks.add_task(analyze_task, request.pattern_count)

    return {
        "success": True,
        "message": "åˆ†æä»»åŠ¡å·²å¯åŠ¨"
    }


@app.get("/api/patterns", response_model=List[AnalysisPattern])
async def get_patterns():
    """è·å–å·²è¯†åˆ«çš„ä¸Šæ¶¨æ¨¡å¼"""
    try:
        patterns = db.get_patterns()
        return patterns
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/predict")
async def predict_stocks(background_tasks: BackgroundTasks):
    """
    åŒºåŸŸ3ï¼šé¢„æµ‹è‚¡ç¥¨ä¸Šæ¶¨æ¦‚ç‡
    æ ¹æ®æœ€è¿‘æ•°æ®å’Œå·²è¯†åˆ«æ¨¡å¼è¿›è¡Œé¢„æµ‹
    """
    # æ£€æŸ¥AIæ˜¯å¦å¯ç”¨
    if not analyzer.ai_enabled:
        logger.error("AIåŠŸèƒ½ä¸å¯ç”¨ï¼šæœªé…ç½®ANTHROPIC_API_KEY")
        return {
            "success": False,
            "message": "AIåŠŸèƒ½ä¸å¯ç”¨ï¼šè¯·é…ç½®ANTHROPIC_API_KEYç¯å¢ƒå˜é‡åé‡å¯æœåŠ¡"
        }

    if task_status["predict"]["running"]:
        return {"success": False, "message": "é¢„æµ‹ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­"}

    def predict_task():
        try:
            task_status["predict"]["running"] = True
            task_status["predict"]["message"] = "è·å–ä¸Šæ¶¨æ¨¡å¼..."
            task_status["predict"]["progress"] = 10

            # è·å–å·²ä¿å­˜çš„æ¨¡å¼
            patterns = db.get_patterns()

            if not patterns:
                task_status["predict"]["message"] = "è¯·å…ˆæ‰§è¡Œæ•°æ®åˆ†æ"
                return

            task_status["predict"]["message"] = "è·å–æœ€è¿‘è‚¡ç¥¨æ•°æ®..."
            task_status["predict"]["progress"] = 30

            # è·å–æ‰€æœ‰è‚¡ç¥¨æœ€è¿‘30å¤©çš„æ•°æ®
            recent_data = db.get_recent_data_all_stocks(days=30)

            if recent_data.empty:
                task_status["predict"]["message"] = "æ²¡æœ‰æ•°æ®"
                return

            task_status["predict"]["message"] = "AIé¢„æµ‹ä¸­..."
            task_status["predict"]["progress"] = 50

            # ä½¿ç”¨ Claude é¢„æµ‹
            predictions = analyzer.predict_stock_probability(recent_data, patterns)

            task_status["predict"]["message"] = f"å®Œæˆï¼æ‰¾åˆ°{len(predictions)}åªæ½œåŠ›è‚¡ç¥¨"
            task_status["predict"]["progress"] = 100

            # ä¿å­˜é¢„æµ‹ç»“æœåˆ°å…¨å±€å˜é‡ï¼ˆç®€åŒ–ç‰ˆï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥å­˜æ•°æ®åº“ï¼‰
            task_status["predict"]["result"] = predictions

        except Exception as e:
            logger.error(f"é¢„æµ‹ä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
            task_status["predict"]["message"] = f"é”™è¯¯: {str(e)}"
            task_status["predict"]["progress"] = 0
        finally:
            task_status["predict"]["running"] = False

    background_tasks.add_task(predict_task)

    return {
        "success": True,
        "message": "é¢„æµ‹ä»»åŠ¡å·²å¯åŠ¨"
    }


@app.get("/api/predictions", response_model=List[StockPrediction])
async def get_predictions(days: int = 1):
    """è·å–é¢„æµ‹ç»“æœ

    ä¼˜å…ˆè¿”å›å†…å­˜ä¸­çš„æœ€æ–°é¢„æµ‹ç»“æœï¼›è‹¥æ— ï¼Œåˆ™ä»æ•°æ®åº“è¯»å–æœ€è¿‘Nå¤©çš„é¢„æµ‹

    Args:
        days: ä»æ•°æ®åº“è¯»å–æœ€è¿‘Nå¤©çš„é¢„æµ‹ï¼ˆé»˜è®¤1å¤©ï¼Œå³æœ€è¿‘ä¸€æ¬¡ï¼‰
    """
    # ä¼˜å…ˆè¿”å›å†…å­˜ä¸­çš„ç»“æœï¼ˆåˆšå®Œæˆçš„é¢„æµ‹ï¼‰
    if "result" in task_status["predict"]:
        logger.info("è¿”å›å†…å­˜ä¸­çš„é¢„æµ‹ç»“æœ")
        return task_status["predict"]["result"]

    # å†…å­˜ä¸­æ— ç»“æœï¼Œä»æ•°æ®åº“è¯»å–æœ€è¿‘ä¸€æ¬¡é¢„æµ‹
    logger.info(f"å†…å­˜ä¸­æ— é¢„æµ‹ç»“æœï¼Œä»æ•°æ®åº“è¯»å–æœ€è¿‘{days}å¤©çš„é¢„æµ‹")
    try:
        predictions_from_db = db.get_predictions(days=days, verified_only=False)

        # è½¬æ¢ä¸ºStockPredictionæ ¼å¼
        result = []
        for pred in predictions_from_db:
            result.append({
                'code': pred['stock_code'],
                'name': pred['stock_name'],
                'probability': pred['probability'],
                'reason': pred['reasoning'],
                'current_price': 0.0,  # å†å²é¢„æµ‹æ— å½“å‰ä»·æ ¼
                'last_date': pred['prediction_date']
            })

        logger.info(f"ä»æ•°æ®åº“è¯»å–åˆ° {len(result)} æ¡é¢„æµ‹è®°å½•")
        return result[:100]  # è¿”å›å‰100æ¡

    except Exception as e:
        logger.error(f"ä»æ•°æ®åº“è¯»å–é¢„æµ‹å¤±è´¥: {e}")
        return []


@app.get("/api/stock/{code}/kline")
async def get_stock_kline(code: str, days: int = 90):
    """è·å–æŒ‡å®šè‚¡ç¥¨çš„Kçº¿æ•°æ®"""
    try:
        df = db.get_stock_data(code, days=days)
        if df.empty:
            return {"code": code, "data": []}

        # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
        kline_data = []
        for _, row in df.iterrows():
            kline_data.append({
                'date': row['date'],
                'open': float(row['open']),
                'high': float(row['high']),
                'low': float(row['low']),
                'close': float(row['close']),
                'volume': float(row['volume'])
            })

        # æŒ‰æ—¥æœŸæ­£åºæ’åˆ—
        kline_data.reverse()

        return {"code": code, "name": df.iloc[0]['name'], "data": kline_data}
    except Exception as e:
        print(f"è·å–Kçº¿æ•°æ®å¤±è´¥ {code}: {e}")
        return {"code": code, "data": []}


# ===== è‚¡ç¥¨æ± ç®¡ç† API =====

@app.post("/api/stock-pool/update")
async def update_stock_pool(background_tasks: BackgroundTasks):
    """æ›´æ–°è‚¡ç¥¨æ± ï¼ˆè·å–ä¸Šäº¤æ‰€æˆåˆ†è‚¡ï¼‰"""
    if task_status.get("update_pool", {}).get("running", False):
        return {"success": False, "message": "è‚¡ç¥¨æ± æ›´æ–°ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­"}

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    if "update_pool" not in task_status:
        task_status["update_pool"] = {"running": False, "progress": 0, "message": ""}

    def update_pool_task():
        try:
            task_status["update_pool"]["running"] = True
            task_status["update_pool"]["message"] = "è·å–ä¸Šäº¤æ‰€æˆåˆ†è‚¡åˆ—è¡¨..."
            task_status["update_pool"]["progress"] = 20

            # è·å–SSEæˆåˆ†è‚¡
            stocks = fetch_sse_component_stocks()

            if not stocks:
                task_status["update_pool"]["message"] = "æœªèƒ½è·å–æˆåˆ†è‚¡åˆ—è¡¨"
                task_status["update_pool"]["progress"] = 0
                return

            task_status["update_pool"]["message"] = f"ä¿å­˜ {len(stocks)} åªè‚¡ç¥¨åˆ°è‚¡ç¥¨æ± ..."
            task_status["update_pool"]["progress"] = 60

            # æ›´æ–°æ•°æ®åº“
            db.update_stock_pool(stocks)

            task_status["update_pool"]["message"] = f"æˆåŠŸï¼è‚¡ç¥¨æ± å·²æ›´æ–°ï¼ˆ{len(stocks)}åªè‚¡ç¥¨ï¼‰"
            task_status["update_pool"]["progress"] = 100

        except Exception as e:
            logger.error(f"è‚¡ç¥¨æ± æ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
            task_status["update_pool"]["message"] = f"é”™è¯¯: {str(e)}"
            task_status["update_pool"]["progress"] = 0
        finally:
            task_status["update_pool"]["running"] = False

    background_tasks.add_task(update_pool_task)

    return {
        "success": True,
        "message": "è‚¡ç¥¨æ± æ›´æ–°ä»»åŠ¡å·²å¯åŠ¨"
    }


@app.get("/api/stock-pool")
async def get_stock_pool():
    """è·å–è‚¡ç¥¨æ± åˆ—è¡¨"""
    try:
        stocks = db.get_stock_pool(active_only=True)
        return {
            "success": True,
            "data": stocks,
            "count": len(stocks)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/stock-pool/status")
async def get_stock_pool_status():
    """æ£€æŸ¥è‚¡ç¥¨æ± çŠ¶æ€"""
    try:
        is_empty = db.is_stock_pool_empty()
        pool_count = 0 if is_empty else len(db.get_stock_pool())

        return {
            "success": True,
            "is_empty": is_empty,
            "count": pool_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)


@app.get("/api/predictions/history")
async def get_prediction_history(days: int = 30, verified_only: bool = False):
    """è·å–å†å²é¢„æµ‹è®°å½•
    
    Args:
        days: è·å–æœ€è¿‘Nå¤©çš„é¢„æµ‹
        verified_only: æ˜¯å¦åªè¿”å›å·²éªŒè¯çš„é¢„æµ‹
    """
    try:
        predictions = db.get_predictions(days=days, verified_only=verified_only)
        return {
            "success": True,
            "data": predictions,
            "count": len(predictions)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/predictions/{prediction_id}/verify")
async def verify_prediction(prediction_id: int, actual_rise: float):
    """éªŒè¯é¢„æµ‹ç»“æœ
    
    Args:
        prediction_id: é¢„æµ‹ID
        actual_rise: å®é™…æ¶¨å¹…(å¦‚0.08è¡¨ç¤º8%)
    """
    try:
        from datetime import datetime
        verified_date = datetime.now().strftime('%Y-%m-%d')
        
        db.verify_prediction(prediction_id, actual_rise, verified_date)
        
        return {
            "success": True,
            "message": "é¢„æµ‹ç»“æœå·²éªŒè¯"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
